# Conclusion, exercises, next steps.

We didn't actually do the task right. DafnyBench proper leaves the source of each sample mostly hardcoded, and only inserts hints. Instead, we had it regenerate _all_ the code in the completion because that is the simplest text-to-text setup. This is of course acceptable when language models are flawless, trustworthy, faithful, and not scruffy looking. But in real life, language models are only one of those things. We should be paranoid that the language model agent might take the opportunity of piping the non-hint code exactly through to make the problem easier for itself.

## Exercises

## Next steps

Onwards, we throw out our code up till this point
